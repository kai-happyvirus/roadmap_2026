# Core Linear Algebra for ML + NumPy Deep Dive

Objective:  
Build strong intuition for **linear algebra operations** (vectors, matrics, dot products, projections) and connect them to **NumPy implementations**.
These are the mathematical foundations for **PyTorch, neural networks, CUDA kernels** and **Transformers**.

1. Watch: "How GPUs works**
This builds your mental model for why GPUs are essential for ML.

ðŸ”— NVIDIA: What is a GPU?
https://blogs.nvidia.com/blog/whats-the-difference-between-a-cpu-and-a-gpu/
https://www.youtube.com/watch?v=LfdK-v0SbGI&t=66s
(Obsoluted instead IBM's GPU youtube.)

2. Read: NumPy Quickstart (10â€“15 min)

Youâ€™ll reinforce matrix operations and shapes.

ðŸ”— NumPy Quickstart Tutorial
https://numpy.org/doc/stable/user/quickstart.html

3. Study Linear Algebra Essentials (20â€“30 min)

Focus only on these concepts today:

Scalars, vectors, matrices, tensors

Matrix multiplication rules

Dot product

Transpose

Identity matrix

Norms (L1, L2)

ðŸ”— Khan Academy (free):
Vectors â†’ https://www.khanacademy.org/math/linear-algebra/vectors-and-spaces

Matrix multiplication â†’ https://www.khanacademy.org/math/linear-algebra/matrix-transformations/matrix_multiplication

(You donâ€™t need to finish the entire playlist â€” just the essentials today.)

